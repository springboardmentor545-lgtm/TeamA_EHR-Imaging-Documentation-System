# -*- coding: utf-8 -*-
"""Preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kEtoNKa7IJehp19dIZX9tsCUAJWQKLqK
"""

from google.colab import files
import zipfile
import io
import os

# This will prompt you to upload your zip file
uploaded = files.upload()

# Get the name of the uploaded file
zip_file_name = list(uploaded.keys())[0]

# Unzip the file
with zipfile.ZipFile(io.BytesIO(uploaded[zip_file_name]), 'r') as zip_ref:
    zip_ref.extractall('medical_images')

# List the files in the extracted directory to make sure it worked
print(os.listdir('medical_images'))

# preprocess.py
import pandas as pd
import numpy as np
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')


def clean_text(text):
    """
    Cleans unwanted characters, extra spaces, and newlines from text.
    """
    if pd.isna(text):
        return ''

    text = str(text).replace('*', '').replace('‚òÖ', '')
    import re
    text = re.sub(r'\n\s*\n', '\n\n', text)

    lines = text.split('\n')
    cleaned_lines = []
    for line in lines:
        if line.strip() == '':
            cleaned_lines.append('')
        else:
            cleaned_lines.append(' '.join(line.split()))
    return '\n'.join(cleaned_lines)


def load_metadata(csv_path='master_metadata.csv'):
    """
    Loads and preprocesses the master metadata CSV file.
    - Cleans text columns
    - Parses date fields
    - Removes duplicates or invalid entries
    - Adds derived columns if needed
    """
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"‚ùå File not found: {csv_path}")

    print("üì• Loading dataset...")
    df = pd.read_csv(csv_path)

    print(f"‚úÖ Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")

    # Clean date format
    if 'Data of Study' in df.columns:
        df['Data of Study'] = pd.to_datetime(df['Data of Study'], format='%m/%d/%Y', errors='coerce')

    # Clean string/text columns
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].apply(clean_text)

    # Drop duplicates if any
    before = len(df)
    df.drop_duplicates(inplace=True)
    after = len(df)
    if before != after:
        print(f"üßπ Removed {before - after} duplicate records.")

    # Handle missing Patient_IDs
    if 'Patient_ID' in df.columns:
        df = df[df['Patient_ID'].notna()]

    # Example: add derived column for patient age group
    if 'Age' in df.columns:
        df['Age_Group'] = pd.cut(
            df['Age'],
            bins=[0, 30, 45, 60, 80, 120],
            labels=['<30', '30-45', '46-60', '61-80', '80+'],
            right=False
        )

    # Add timestamp of cleaning
    df['Processed_Timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    return df


def save_cleaned_metadata(df, output_path='cleaned_metadata.csv'):
    """
    Saves the cleaned metadata dataframe to a CSV file.
    """
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False, encoding='utf-8')
    print(f"üíæ Cleaned metadata saved to: {output_path}")


if __name__ == "__main__":
    print("ü©∫ Cardiac Imaging Data Preprocessing Module")
    print("=" * 50)

    try:
        df = load_metadata()
        save_cleaned_metadata(df)
        print("\n‚úÖ Preprocessing complete for all patient data.")
        print(f"Total records processed: {len(df)}")
        print(f"Preview:\n{df.head()}")
    except Exception as e:
        print(f"‚ùå Error: {e}")